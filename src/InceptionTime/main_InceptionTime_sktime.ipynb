{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test surrogate augmentation on InceptionTimeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some imports \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # hide some annoying deprication warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data_utils  \n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "\n",
    "random.seed(24569)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'ArrowHead', 'BME', 'Beef', 'BeetleFly', 'BirdChicken', 'CBF', 'Car', 'Chinatown', 'ChlorineConcentration', 'CinCECGtorso', 'Coffee', 'Computers', 'CricketX', 'CricketY', 'CricketZ', 'Crop', 'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', 'ECG200', 'ECG5000', 'ECGFiveDays', 'EOGHorizontalSignal', 'EOGVerticalSignal', 'Earthquakes', 'ElectricDevices', 'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords', 'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain', 'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham', 'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate', 'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian', 'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', 'MixedShapes', 'MixedShapesSmallTrain', 'MoteStrain', 'NonInvasiveFetalECGThorax1', 'NonInvasiveFetalECGThorax2', 'OSULeaf', 'OliveOil', 'PLAID', 'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ', 'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'Plane', 'PowerCons', 'ProximalPhalanxOutlineAgeGroup', 'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', 'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2', 'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ', 'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarlightCurves', 'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl', 'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG', 'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX', 'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine', 'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:31<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name  train_size  test_size  length  test_balance   \n",
      "0                 ACSF1         100        100    1460      0.500000  \\\n",
      "1                 Adiac         390        391     176      0.350000   \n",
      "2    AllGestureWiimoteX         300        700     500      0.500000   \n",
      "3    AllGestureWiimoteY         300        700     500      0.500000   \n",
      "4    AllGestureWiimoteZ         300        700     500      0.500000   \n",
      "..                  ...         ...        ...     ...           ...   \n",
      "123                Wine          57         54     234      0.500000   \n",
      "124        WordSynonyms         267        638     270      0.090909   \n",
      "125               Worms         181         77     900      0.717391   \n",
      "126       WormsTwoClass         181         77     900      0.428571   \n",
      "127                Yoga         300       3000     426      0.464333   \n",
      "\n",
      "     nr_classes  \n",
      "0            10  \n",
      "1            37  \n",
      "2            10  \n",
      "3            10  \n",
      "4            10  \n",
      "..          ...  \n",
      "123           2  \n",
      "124          25  \n",
      "125           5  \n",
      "126           2  \n",
      "127           2  \n",
      "\n",
      "[128 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "import load_data as dataloader\n",
    "from pyts.datasets import ucr_dataset_list\n",
    "\n",
    "dataset_name_list = ucr_dataset_list()\n",
    "print(dataset_name_list)  \n",
    "CACHED_DATA_FOLDER = os.path.join(os.path.dirname(os.getcwd()), \"Data\")\n",
    "dataset_list = []\n",
    "for dataset_name in tqdm.tqdm(dataset_name_list):\n",
    "    cache_path = os.path.join(CACHED_DATA_FOLDER, dataset_name)\n",
    "    datset = dataloader.fetch_ucr_dataset(dataset=dataset_name, use_cache=True, data_home=cache_path)\n",
    "    dataset_list.append(datset)\n",
    "\n",
    "\n",
    "## Create pandas dataframe\n",
    "dataset_list_binary = []\n",
    "dataset_train_size = []\n",
    "dataset_test_size = []\n",
    "datset_length = []\n",
    "binary_dataset_name = []\n",
    "test_balance = []\n",
    "num_classes = []\n",
    "\n",
    "for i,dataset_object in enumerate(dataset_list):\n",
    "    # Filter the datasets depending on number of classes\n",
    "    nclasses = len(np.unique(dataset_object['target_train']))\n",
    "    #if num_clases < 3:\n",
    "    \n",
    "    name = dataset_name_list[i]\n",
    "    dataset_list_binary.append(dataset_object)\n",
    "    data_length = dataset_object['data_train'].shape[1]\n",
    "    train_size = dataset_object['data_train'].shape[0]\n",
    "    test_size = dataset_object['data_test'].shape[0]\n",
    "    (labels,counts) = np.unique(dataset_object['target_test'],return_counts=True)\n",
    "    test_proportion = counts[0]/(counts[0]+counts[1])\n",
    "\n",
    "    datset_length.append(data_length)\n",
    "    dataset_train_size.append(train_size)\n",
    "    dataset_test_size.append(test_size)\n",
    "    binary_dataset_name.append(name)\n",
    "    test_balance.append(test_proportion)\n",
    "    num_classes.append(nclasses)\n",
    "\n",
    "meta_data = {'name': binary_dataset_name, 'train_size': dataset_train_size, 'test_size': dataset_test_size,'length':datset_length, 'test_balance':test_balance, \"nr_classes\":num_classes}\n",
    "meta_df = pd.DataFrame(data=meta_data)\n",
    "print(meta_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out datasets of reasonable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "                               name  train_size  test_size  length   \n",
      "1                             Adiac         390        391     176  \\\n",
      "16                        Computers         250        250     720   \n",
      "17                         CricketX         390        390     300   \n",
      "18                         CricketY         390        390     300   \n",
      "19                         CricketZ         390        390     300   \n",
      "22     DistalPhalanxOutlineAgeGroup         400        139      80   \n",
      "23      DistalPhalanxOutlineCorrect         600        276      80   \n",
      "24                  DistalPhalanxTW         400        139      80   \n",
      "33                      Earthquakes         322        139     512   \n",
      "39                       FiftyWords         450        455     270   \n",
      "46                  GestureMidAirD1         208        130     360   \n",
      "47                  GestureMidAirD2         208        130     360   \n",
      "48                  GestureMidAirD3         208        130     360   \n",
      "65           LargeKitchenAppliances         375        375     720   \n",
      "70                    MedicalImages         381        760      99   \n",
      "72     MiddlePhalanxOutlineAgeGroup         400        154      80   \n",
      "73      MiddlePhalanxOutlineCorrect         600        291      80   \n",
      "74                  MiddlePhalanxTW         399        154      80   \n",
      "78       NonInvasiveFetalECGThorax1        1800       1965     750   \n",
      "79       NonInvasiveFetalECGThorax2        1800       1965     750   \n",
      "83         PhalangesOutlinesCorrect        1800        858      80   \n",
      "91   ProximalPhalanxOutlineAgeGroup         400        205      80   \n",
      "92    ProximalPhalanxOutlineCorrect         600        291      80   \n",
      "93                ProximalPhalanxTW         400        205      80   \n",
      "94             RefrigerationDevices         375        375     720   \n",
      "96                       ScreenType         375        375     720   \n",
      "102                       ShapesAll         600        600     512   \n",
      "103          SmallKitchenAppliances         375        375     720   \n",
      "108                      Strawberry         613        370     235   \n",
      "109                     SwedishLeaf         500        625     128   \n",
      "111                SyntheticControl         300        300      60   \n",
      "\n",
      "     test_balance  nr_classes  \n",
      "1        0.350000          37  \n",
      "16       0.500000           2  \n",
      "17       0.442623          12  \n",
      "18       0.544118          12  \n",
      "19       0.464789          12  \n",
      "22       0.202703           3  \n",
      "23       0.416667           2  \n",
      "24       0.486486           6  \n",
      "33       0.748201           2  \n",
      "39       0.575758          50  \n",
      "46       0.500000          26  \n",
      "47       0.500000          26  \n",
      "48       0.500000          26  \n",
      "65       0.500000           3  \n",
      "70       0.606299          10  \n",
      "72       0.296000           3  \n",
      "73       0.429553           2  \n",
      "74       0.362319           6  \n",
      "78       0.551724          42  \n",
      "79       0.551724          42  \n",
      "83       0.386946           2  \n",
      "91       0.161905           3  \n",
      "92       0.316151           2  \n",
      "93       0.028986           6  \n",
      "94       0.500000           3  \n",
      "96       0.500000           3  \n",
      "102      0.500000          60  \n",
      "103      0.500000           3  \n",
      "108      0.356757           2  \n",
      "109      0.541176          15  \n",
      "111      0.500000           6  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "reasonable_datasets = meta_df.loc[(meta_df['train_size']>200)&(meta_df['train_size']<2000)& (meta_df['test_size']<2*meta_df['train_size']) & (meta_df['length']<1000)]\n",
    "print(reasonable_datasets.shape[0])\n",
    "print(reasonable_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training/Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indx = 91    #corresponds to ProximalPhalanxOutlineAgeGroup dataset\n",
    "\n",
    "dataset_obj = dataset_list[indx]\n",
    "\n",
    "x_train = dataset_obj['data_train']\n",
    "y_train = dataset_obj['target_train']\n",
    "x_test = dataset_obj['data_test']\n",
    "y_test = dataset_obj['target_test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training/Testing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data using sktime.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape is (60, 577)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset = \"Car\"\n",
    "X_train, y_train = load_UCR_UEA_dataset(name=dataset, split=\"train\", return_X_y=True, return_type=\"numpy2d\")\n",
    "X_test, y_test = load_UCR_UEA_dataset(name=dataset, split=\"test\", return_X_y=True, return_type=\"numpy2d\")\n",
    "\n",
    "print(\"Training data shape is\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_training(val_losses):\n",
    "    \"\"\"This function is to be used for early stopping during training. \n",
    "    Input: val_loss, an array containing the calculated validation losses over epochs. \n",
    "    Output: returns True if the training should stop, False if the training should continue\"\"\"\n",
    "\n",
    "    # If function is called in the early stages of training\n",
    "    if len(val_losses)<10:\n",
    "        return False\n",
    "    \n",
    "    # Check if validation loss or accuracy loss have basically stopped changing the last 5 epochs\n",
    "    tolerance = 1e-3    # saw docs for stopping_tolerance by h20.ai, they used this as default tolerance\n",
    "    n_epochs = len(val_losses)\n",
    "    loss_avg = np.mean(val_losses[n_epochs-7:n_epochs-2])\n",
    "\n",
    "    if np.abs(val_losses[-1]-loss_avg) < tolerance:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 80, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d_90 (MaxPooling1D  (None, 80, 1)       0           ['input_16[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_465 (Conv1D)            (None, 80, 16)       256         ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_466 (Conv1D)            (None, 80, 16)       128         ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_467 (Conv1D)            (None, 80, 16)       64          ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_468 (Conv1D)            (None, 80, 16)       16          ['max_pooling1d_90[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_90 (Concatenate)   (None, 80, 64)       0           ['conv1d_465[0][0]',             \n",
      "                                                                  'conv1d_466[0][0]',             \n",
      "                                                                  'conv1d_467[0][0]',             \n",
      "                                                                  'conv1d_468[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 80, 64)      256         ['concatenate_90[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 80, 64)       0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_469 (Conv1D)            (None, 80, 16)       1024        ['activation_120[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_91 (MaxPooling1D  (None, 80, 64)      0           ['activation_120[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_470 (Conv1D)            (None, 80, 16)       4096        ['conv1d_469[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_471 (Conv1D)            (None, 80, 16)       2048        ['conv1d_469[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_472 (Conv1D)            (None, 80, 16)       1024        ['conv1d_469[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_473 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_91[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_91 (Concatenate)   (None, 80, 64)       0           ['conv1d_470[0][0]',             \n",
      "                                                                  'conv1d_471[0][0]',             \n",
      "                                                                  'conv1d_472[0][0]',             \n",
      "                                                                  'conv1d_473[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 80, 64)      256         ['concatenate_91[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 80, 64)       0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_474 (Conv1D)            (None, 80, 16)       1024        ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_92 (MaxPooling1D  (None, 80, 64)      0           ['activation_121[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_475 (Conv1D)            (None, 80, 16)       4096        ['conv1d_474[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_476 (Conv1D)            (None, 80, 16)       2048        ['conv1d_474[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_477 (Conv1D)            (None, 80, 16)       1024        ['conv1d_474[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_478 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_92[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_92 (Concatenate)   (None, 80, 64)       0           ['conv1d_475[0][0]',             \n",
      "                                                                  'conv1d_476[0][0]',             \n",
      "                                                                  'conv1d_477[0][0]',             \n",
      "                                                                  'conv1d_478[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_479 (Conv1D)            (None, 80, 64)       64          ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 80, 64)      256         ['concatenate_92[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 80, 64)      256         ['conv1d_479[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 80, 64)       0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 80, 64)       0           ['batch_normalization_123[0][0]',\n",
      "                                                                  'activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 80, 64)       0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_480 (Conv1D)            (None, 80, 16)       1024        ['activation_123[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_93 (MaxPooling1D  (None, 80, 64)      0           ['activation_123[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_481 (Conv1D)            (None, 80, 16)       4096        ['conv1d_480[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_482 (Conv1D)            (None, 80, 16)       2048        ['conv1d_480[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_483 (Conv1D)            (None, 80, 16)       1024        ['conv1d_480[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_484 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_93[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_93 (Concatenate)   (None, 80, 64)       0           ['conv1d_481[0][0]',             \n",
      "                                                                  'conv1d_482[0][0]',             \n",
      "                                                                  'conv1d_483[0][0]',             \n",
      "                                                                  'conv1d_484[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 80, 64)      256         ['concatenate_93[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 80, 64)       0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_485 (Conv1D)            (None, 80, 16)       1024        ['activation_124[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_94 (MaxPooling1D  (None, 80, 64)      0           ['activation_124[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_486 (Conv1D)            (None, 80, 16)       4096        ['conv1d_485[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_487 (Conv1D)            (None, 80, 16)       2048        ['conv1d_485[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_488 (Conv1D)            (None, 80, 16)       1024        ['conv1d_485[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_489 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_94[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 80, 64)       0           ['conv1d_486[0][0]',             \n",
      "                                                                  'conv1d_487[0][0]',             \n",
      "                                                                  'conv1d_488[0][0]',             \n",
      "                                                                  'conv1d_489[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 80, 64)      256         ['concatenate_94[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 80, 64)       0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_490 (Conv1D)            (None, 80, 16)       1024        ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_95 (MaxPooling1D  (None, 80, 64)      0           ['activation_125[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_491 (Conv1D)            (None, 80, 16)       4096        ['conv1d_490[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_492 (Conv1D)            (None, 80, 16)       2048        ['conv1d_490[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_493 (Conv1D)            (None, 80, 16)       1024        ['conv1d_490[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_494 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_95[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 80, 64)       0           ['conv1d_491[0][0]',             \n",
      "                                                                  'conv1d_492[0][0]',             \n",
      "                                                                  'conv1d_493[0][0]',             \n",
      "                                                                  'conv1d_494[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_495 (Conv1D)            (None, 80, 64)       4096        ['activation_123[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 80, 64)      256         ['concatenate_95[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 80, 64)      256         ['conv1d_495[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 80, 64)       0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 80, 64)       0           ['batch_normalization_127[0][0]',\n",
      "                                                                  'activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 80, 64)       0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 64)          0           ['activation_127[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 3)            195         ['global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,947\n",
      "Trainable params: 51,923\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 8s 288ms/step - loss: 1.4188 - accuracy: 0.0793 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.8847 - accuracy: 0.7073 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.6293 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.5016 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.4347 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.4113 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.3933 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 1s 138ms/step - loss: 0.3693 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.3787 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.3468 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.3354 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.3420 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.3232 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3100 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.3133 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.3011 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2972 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2804 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2797 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2809 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2701 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2684 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2578 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2484 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2568 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2389 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.2441 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.2273 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.2408 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 0.2476 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.2232 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2421 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.2279 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.2198 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2154 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2353 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2100 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.2108 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2245 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1975 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.1871 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1810 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1837 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1674 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1527 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1760 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1575 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1532 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.1453 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1589 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1537 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1514 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1316 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.1314 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.1254 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.1382 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1569 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.1348 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.1278 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1516 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.1283 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.1123 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 0.1204 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 1s 160ms/step - loss: 0.0898 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 0.0934 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 0.0881 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.0808 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.1150 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.1299 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 0.1173 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.0866 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0984 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.0624 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0846 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.0689 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.0673 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 1s 141ms/step - loss: 0.0872 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0613 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 1s 146ms/step - loss: 0.0619 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.0606 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0752 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0436 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.0610 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.0792 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.0890 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0806 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0678 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0554 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.0443 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.0367 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0367 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0246 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0295 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0407 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.0405 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0576 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0541 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0509 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0294 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0254 - accuracy: 1.0000 - lr: 0.0010\n",
      "1/1 [==============================] - 1s 772ms/step\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 80, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d_96 (MaxPooling1D  (None, 80, 1)       0           ['input_17[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_496 (Conv1D)            (None, 80, 16)       256         ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_497 (Conv1D)            (None, 80, 16)       128         ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_498 (Conv1D)            (None, 80, 16)       64          ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_499 (Conv1D)            (None, 80, 16)       16          ['max_pooling1d_96[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_96 (Concatenate)   (None, 80, 64)       0           ['conv1d_496[0][0]',             \n",
      "                                                                  'conv1d_497[0][0]',             \n",
      "                                                                  'conv1d_498[0][0]',             \n",
      "                                                                  'conv1d_499[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 80, 64)      256         ['concatenate_96[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 80, 64)       0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_500 (Conv1D)            (None, 80, 16)       1024        ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_97 (MaxPooling1D  (None, 80, 64)      0           ['activation_128[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_501 (Conv1D)            (None, 80, 16)       4096        ['conv1d_500[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_502 (Conv1D)            (None, 80, 16)       2048        ['conv1d_500[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_503 (Conv1D)            (None, 80, 16)       1024        ['conv1d_500[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_504 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_97[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_97 (Concatenate)   (None, 80, 64)       0           ['conv1d_501[0][0]',             \n",
      "                                                                  'conv1d_502[0][0]',             \n",
      "                                                                  'conv1d_503[0][0]',             \n",
      "                                                                  'conv1d_504[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 80, 64)      256         ['concatenate_97[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 80, 64)       0           ['batch_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_505 (Conv1D)            (None, 80, 16)       1024        ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_98 (MaxPooling1D  (None, 80, 64)      0           ['activation_129[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_506 (Conv1D)            (None, 80, 16)       4096        ['conv1d_505[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_507 (Conv1D)            (None, 80, 16)       2048        ['conv1d_505[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_508 (Conv1D)            (None, 80, 16)       1024        ['conv1d_505[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_509 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_98[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_98 (Concatenate)   (None, 80, 64)       0           ['conv1d_506[0][0]',             \n",
      "                                                                  'conv1d_507[0][0]',             \n",
      "                                                                  'conv1d_508[0][0]',             \n",
      "                                                                  'conv1d_509[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_510 (Conv1D)            (None, 80, 64)       64          ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 80, 64)      256         ['concatenate_98[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 80, 64)      256         ['conv1d_510[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 80, 64)       0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 80, 64)       0           ['batch_normalization_131[0][0]',\n",
      "                                                                  'activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 80, 64)       0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_511 (Conv1D)            (None, 80, 16)       1024        ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_99 (MaxPooling1D  (None, 80, 64)      0           ['activation_131[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_512 (Conv1D)            (None, 80, 16)       4096        ['conv1d_511[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_513 (Conv1D)            (None, 80, 16)       2048        ['conv1d_511[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_514 (Conv1D)            (None, 80, 16)       1024        ['conv1d_511[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_515 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_99[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_99 (Concatenate)   (None, 80, 64)       0           ['conv1d_512[0][0]',             \n",
      "                                                                  'conv1d_513[0][0]',             \n",
      "                                                                  'conv1d_514[0][0]',             \n",
      "                                                                  'conv1d_515[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 80, 64)      256         ['concatenate_99[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 80, 64)       0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_516 (Conv1D)            (None, 80, 16)       1024        ['activation_132[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_100 (MaxPooling1  (None, 80, 64)      0           ['activation_132[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_517 (Conv1D)            (None, 80, 16)       4096        ['conv1d_516[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_518 (Conv1D)            (None, 80, 16)       2048        ['conv1d_516[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_519 (Conv1D)            (None, 80, 16)       1024        ['conv1d_516[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_520 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_100[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_100 (Concatenate)  (None, 80, 64)       0           ['conv1d_517[0][0]',             \n",
      "                                                                  'conv1d_518[0][0]',             \n",
      "                                                                  'conv1d_519[0][0]',             \n",
      "                                                                  'conv1d_520[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 80, 64)      256         ['concatenate_100[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 80, 64)       0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_521 (Conv1D)            (None, 80, 16)       1024        ['activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_101 (MaxPooling1  (None, 80, 64)      0           ['activation_133[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_522 (Conv1D)            (None, 80, 16)       4096        ['conv1d_521[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_523 (Conv1D)            (None, 80, 16)       2048        ['conv1d_521[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_524 (Conv1D)            (None, 80, 16)       1024        ['conv1d_521[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_525 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_101[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_101 (Concatenate)  (None, 80, 64)       0           ['conv1d_522[0][0]',             \n",
      "                                                                  'conv1d_523[0][0]',             \n",
      "                                                                  'conv1d_524[0][0]',             \n",
      "                                                                  'conv1d_525[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_526 (Conv1D)            (None, 80, 64)       4096        ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 80, 64)      256         ['concatenate_101[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 80, 64)      256         ['conv1d_526[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 80, 64)       0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 80, 64)       0           ['batch_normalization_135[0][0]',\n",
      "                                                                  'activation_134[0][0]']         \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 80, 64)       0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_16 (G  (None, 64)          0           ['activation_135[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 3)            195         ['global_average_pooling1d_16[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,947\n",
      "Trainable params: 51,923\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 8s 155ms/step - loss: 0.9876 - accuracy: 0.5976 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.6527 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.5460 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.5115 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.5414 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.4935 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.4619 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.4340 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.4216 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.4156 - accuracy: 0.8476 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.3856 - accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.3707 - accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.3550 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.3549 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.3407 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.3420 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3248 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.3385 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.3410 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3311 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3014 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.2973 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2865 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 1s 164ms/step - loss: 0.2720 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.2766 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.2786 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.3020 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 1s 164ms/step - loss: 0.2658 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2696 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2631 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.2481 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.2442 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.2219 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2303 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.2217 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2003 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.1890 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.1656 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.1850 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.1605 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.1598 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.1498 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.1586 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.1793 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.2595 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.2099 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.1720 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.1555 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.1329 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.1220 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 0.1236 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 0.1054 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 0.0956 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0926 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.0782 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.0664 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.0584 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0766 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0571 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.0485 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.0471 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 0.0392 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0345 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 1s 143ms/step - loss: 0.0363 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.0724 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.0648 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.0451 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.0705 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.0542 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0791 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0818 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.1654 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.0904 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 0.0971 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 1s 160ms/step - loss: 0.0944 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0769 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.0803 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0583 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0782 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0629 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0809 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0541 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 1s 145ms/step - loss: 0.0468 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0312 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.0309 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.0312 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0214 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0207 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.0147 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.0159 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.0170 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 1s 151ms/step - loss: 0.0167 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.0179 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.0108 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0128 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0117 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0162 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0167 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 0.0103 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 1s 160ms/step - loss: 0.0209 - accuracy: 1.0000 - lr: 0.0010\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002418D15B940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None, 80, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d_102 (MaxPooling1  (None, 80, 1)       0           ['input_18[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_527 (Conv1D)            (None, 80, 16)       256         ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_528 (Conv1D)            (None, 80, 16)       128         ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_529 (Conv1D)            (None, 80, 16)       64          ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_530 (Conv1D)            (None, 80, 16)       16          ['max_pooling1d_102[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_102 (Concatenate)  (None, 80, 64)       0           ['conv1d_527[0][0]',             \n",
      "                                                                  'conv1d_528[0][0]',             \n",
      "                                                                  'conv1d_529[0][0]',             \n",
      "                                                                  'conv1d_530[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 80, 64)      256         ['concatenate_102[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 80, 64)       0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_531 (Conv1D)            (None, 80, 16)       1024        ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_103 (MaxPooling1  (None, 80, 64)      0           ['activation_136[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_532 (Conv1D)            (None, 80, 16)       4096        ['conv1d_531[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_533 (Conv1D)            (None, 80, 16)       2048        ['conv1d_531[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_534 (Conv1D)            (None, 80, 16)       1024        ['conv1d_531[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_535 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_103[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 80, 64)       0           ['conv1d_532[0][0]',             \n",
      "                                                                  'conv1d_533[0][0]',             \n",
      "                                                                  'conv1d_534[0][0]',             \n",
      "                                                                  'conv1d_535[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 80, 64)      256         ['concatenate_103[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 80, 64)       0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_536 (Conv1D)            (None, 80, 16)       1024        ['activation_137[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_104 (MaxPooling1  (None, 80, 64)      0           ['activation_137[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_537 (Conv1D)            (None, 80, 16)       4096        ['conv1d_536[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_538 (Conv1D)            (None, 80, 16)       2048        ['conv1d_536[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_539 (Conv1D)            (None, 80, 16)       1024        ['conv1d_536[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_540 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_104[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 80, 64)       0           ['conv1d_537[0][0]',             \n",
      "                                                                  'conv1d_538[0][0]',             \n",
      "                                                                  'conv1d_539[0][0]',             \n",
      "                                                                  'conv1d_540[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_541 (Conv1D)            (None, 80, 64)       64          ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 80, 64)      256         ['concatenate_104[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 80, 64)      256         ['conv1d_541[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 80, 64)       0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 80, 64)       0           ['batch_normalization_139[0][0]',\n",
      "                                                                  'activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 80, 64)       0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_542 (Conv1D)            (None, 80, 16)       1024        ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_105 (MaxPooling1  (None, 80, 64)      0           ['activation_139[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_543 (Conv1D)            (None, 80, 16)       4096        ['conv1d_542[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_544 (Conv1D)            (None, 80, 16)       2048        ['conv1d_542[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_545 (Conv1D)            (None, 80, 16)       1024        ['conv1d_542[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_546 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_105[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_105 (Concatenate)  (None, 80, 64)       0           ['conv1d_543[0][0]',             \n",
      "                                                                  'conv1d_544[0][0]',             \n",
      "                                                                  'conv1d_545[0][0]',             \n",
      "                                                                  'conv1d_546[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 80, 64)      256         ['concatenate_105[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 80, 64)       0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_547 (Conv1D)            (None, 80, 16)       1024        ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_106 (MaxPooling1  (None, 80, 64)      0           ['activation_140[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_548 (Conv1D)            (None, 80, 16)       4096        ['conv1d_547[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_549 (Conv1D)            (None, 80, 16)       2048        ['conv1d_547[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_550 (Conv1D)            (None, 80, 16)       1024        ['conv1d_547[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_551 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_106[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_106 (Concatenate)  (None, 80, 64)       0           ['conv1d_548[0][0]',             \n",
      "                                                                  'conv1d_549[0][0]',             \n",
      "                                                                  'conv1d_550[0][0]',             \n",
      "                                                                  'conv1d_551[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 80, 64)      256         ['concatenate_106[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 80, 64)       0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_552 (Conv1D)            (None, 80, 16)       1024        ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_107 (MaxPooling1  (None, 80, 64)      0           ['activation_141[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_553 (Conv1D)            (None, 80, 16)       4096        ['conv1d_552[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_554 (Conv1D)            (None, 80, 16)       2048        ['conv1d_552[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_555 (Conv1D)            (None, 80, 16)       1024        ['conv1d_552[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_556 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_107[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_107 (Concatenate)  (None, 80, 64)       0           ['conv1d_553[0][0]',             \n",
      "                                                                  'conv1d_554[0][0]',             \n",
      "                                                                  'conv1d_555[0][0]',             \n",
      "                                                                  'conv1d_556[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_557 (Conv1D)            (None, 80, 64)       4096        ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 80, 64)      256         ['concatenate_107[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 80, 64)      256         ['conv1d_557[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 80, 64)       0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 80, 64)       0           ['batch_normalization_143[0][0]',\n",
      "                                                                  'activation_142[0][0]']         \n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 80, 64)       0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_17 (G  (None, 64)          0           ['activation_143[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 3)            195         ['global_average_pooling1d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,947\n",
      "Trainable params: 51,923\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 8s 163ms/step - loss: 1.3809 - accuracy: 0.4268 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.8866 - accuracy: 0.6646 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.6636 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.5659 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.5386 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.5216 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.4934 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.4799 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.4630 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.4495 - accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.4212 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.4155 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.4175 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.3865 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.3867 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.3649 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.3703 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.3440 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.3435 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.3311 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 0.3279 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.3211 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.3013 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3076 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 1s 151ms/step - loss: 0.2841 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2939 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.2788 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 1s 151ms/step - loss: 0.3017 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.2648 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.2675 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.2724 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.2632 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2633 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.2640 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.2697 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.2355 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.2328 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.2081 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.2009 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.1934 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.2683 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.2548 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.2090 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.3469 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.2392 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.2103 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.2058 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.2168 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 1s 164ms/step - loss: 0.2863 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.2206 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.2059 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.1937 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.1942 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.2047 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.2117 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.1934 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.1762 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.1849 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.1563 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.1578 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.1328 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 1s 160ms/step - loss: 0.1331 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 0.1335 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.1482 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.1523 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.1085 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.1030 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 1s 151ms/step - loss: 0.1080 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.0931 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.1007 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.1146 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.1988 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.1475 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.1360 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.1118 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0982 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1049 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0900 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1025 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0991 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0919 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0882 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0537 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 1s 144ms/step - loss: 0.0682 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0450 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0542 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0355 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0335 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0322 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0324 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0253 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0211 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0183 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0236 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0178 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0196 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0151 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0155 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0121 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0221 - accuracy: 0.9939 - lr: 0.0010\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002418A12F820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 80, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d_108 (MaxPooling1  (None, 80, 1)       0           ['input_19[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_558 (Conv1D)            (None, 80, 16)       256         ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_559 (Conv1D)            (None, 80, 16)       128         ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_560 (Conv1D)            (None, 80, 16)       64          ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_561 (Conv1D)            (None, 80, 16)       16          ['max_pooling1d_108[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_108 (Concatenate)  (None, 80, 64)       0           ['conv1d_558[0][0]',             \n",
      "                                                                  'conv1d_559[0][0]',             \n",
      "                                                                  'conv1d_560[0][0]',             \n",
      "                                                                  'conv1d_561[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 80, 64)      256         ['concatenate_108[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 80, 64)       0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_562 (Conv1D)            (None, 80, 16)       1024        ['activation_144[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_109 (MaxPooling1  (None, 80, 64)      0           ['activation_144[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_563 (Conv1D)            (None, 80, 16)       4096        ['conv1d_562[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_564 (Conv1D)            (None, 80, 16)       2048        ['conv1d_562[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_565 (Conv1D)            (None, 80, 16)       1024        ['conv1d_562[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_566 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_109[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_109 (Concatenate)  (None, 80, 64)       0           ['conv1d_563[0][0]',             \n",
      "                                                                  'conv1d_564[0][0]',             \n",
      "                                                                  'conv1d_565[0][0]',             \n",
      "                                                                  'conv1d_566[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 80, 64)      256         ['concatenate_109[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 80, 64)       0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_567 (Conv1D)            (None, 80, 16)       1024        ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_110 (MaxPooling1  (None, 80, 64)      0           ['activation_145[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_568 (Conv1D)            (None, 80, 16)       4096        ['conv1d_567[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_569 (Conv1D)            (None, 80, 16)       2048        ['conv1d_567[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_570 (Conv1D)            (None, 80, 16)       1024        ['conv1d_567[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_571 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_110[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_110 (Concatenate)  (None, 80, 64)       0           ['conv1d_568[0][0]',             \n",
      "                                                                  'conv1d_569[0][0]',             \n",
      "                                                                  'conv1d_570[0][0]',             \n",
      "                                                                  'conv1d_571[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_572 (Conv1D)            (None, 80, 64)       64          ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 80, 64)      256         ['concatenate_110[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 80, 64)      256         ['conv1d_572[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 80, 64)       0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 80, 64)       0           ['batch_normalization_147[0][0]',\n",
      "                                                                  'activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 80, 64)       0           ['add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_573 (Conv1D)            (None, 80, 16)       1024        ['activation_147[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_111 (MaxPooling1  (None, 80, 64)      0           ['activation_147[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_574 (Conv1D)            (None, 80, 16)       4096        ['conv1d_573[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_575 (Conv1D)            (None, 80, 16)       2048        ['conv1d_573[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_576 (Conv1D)            (None, 80, 16)       1024        ['conv1d_573[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_577 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_111[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_111 (Concatenate)  (None, 80, 64)       0           ['conv1d_574[0][0]',             \n",
      "                                                                  'conv1d_575[0][0]',             \n",
      "                                                                  'conv1d_576[0][0]',             \n",
      "                                                                  'conv1d_577[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 80, 64)      256         ['concatenate_111[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 80, 64)       0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_578 (Conv1D)            (None, 80, 16)       1024        ['activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_112 (MaxPooling1  (None, 80, 64)      0           ['activation_148[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_579 (Conv1D)            (None, 80, 16)       4096        ['conv1d_578[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_580 (Conv1D)            (None, 80, 16)       2048        ['conv1d_578[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_581 (Conv1D)            (None, 80, 16)       1024        ['conv1d_578[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_582 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_112[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_112 (Concatenate)  (None, 80, 64)       0           ['conv1d_579[0][0]',             \n",
      "                                                                  'conv1d_580[0][0]',             \n",
      "                                                                  'conv1d_581[0][0]',             \n",
      "                                                                  'conv1d_582[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 80, 64)      256         ['concatenate_112[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 80, 64)       0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_583 (Conv1D)            (None, 80, 16)       1024        ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_113 (MaxPooling1  (None, 80, 64)      0           ['activation_149[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_584 (Conv1D)            (None, 80, 16)       4096        ['conv1d_583[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_585 (Conv1D)            (None, 80, 16)       2048        ['conv1d_583[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_586 (Conv1D)            (None, 80, 16)       1024        ['conv1d_583[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_587 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_113[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_113 (Concatenate)  (None, 80, 64)       0           ['conv1d_584[0][0]',             \n",
      "                                                                  'conv1d_585[0][0]',             \n",
      "                                                                  'conv1d_586[0][0]',             \n",
      "                                                                  'conv1d_587[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_588 (Conv1D)            (None, 80, 64)       4096        ['activation_147[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 80, 64)      256         ['concatenate_113[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 80, 64)      256         ['conv1d_588[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 80, 64)       0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 80, 64)       0           ['batch_normalization_151[0][0]',\n",
      "                                                                  'activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 80, 64)       0           ['add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_18 (G  (None, 64)          0           ['activation_151[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 3)            195         ['global_average_pooling1d_18[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,947\n",
      "Trainable params: 51,923\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 6s 131ms/step - loss: 1.2968 - accuracy: 0.3354 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.8132 - accuracy: 0.7012 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.6206 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.5306 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.5321 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.5077 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.5033 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.5326 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4810 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4721 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4594 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4452 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.4324 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.4237 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.4159 - accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3989 - accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4525 - accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4406 - accuracy: 0.8476 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.4623 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4433 - accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.4374 - accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4052 - accuracy: 0.8659 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.3864 - accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.3808 - accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3881 - accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.3746 - accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.3814 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3635 - accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3819 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3699 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3462 - accuracy: 0.8659 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3381 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3394 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3436 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.3297 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3156 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3148 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3211 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3321 - accuracy: 0.8659 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3319 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3147 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.3048 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 0.3188 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.3255 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.3131 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 0.3218 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.2747 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.2709 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 1s 151ms/step - loss: 0.2730 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.3223 - accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.3111 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 0.2994 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.2917 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 1s 272ms/step - loss: 0.2703 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.2499 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.2540 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2278 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2113 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.2171 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.1972 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2188 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2129 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1932 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2158 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 1s 146ms/step - loss: 0.2138 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1860 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1782 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2114 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1954 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1828 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2237 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1947 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1640 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1609 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1566 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1481 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1403 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1154 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0981 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1049 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 1s 144ms/step - loss: 0.1636 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1398 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0858 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1079 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0946 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0995 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0764 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0861 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0812 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0661 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1291 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0979 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2137 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.1706 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1286 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1308 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1043 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0776 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0697 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0659 - accuracy: 1.0000 - lr: 0.0010\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)          [(None, 80, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d_114 (MaxPooling1  (None, 80, 1)       0           ['input_20[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_589 (Conv1D)            (None, 80, 16)       256         ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_590 (Conv1D)            (None, 80, 16)       128         ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_591 (Conv1D)            (None, 80, 16)       64          ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_592 (Conv1D)            (None, 80, 16)       16          ['max_pooling1d_114[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_114 (Concatenate)  (None, 80, 64)       0           ['conv1d_589[0][0]',             \n",
      "                                                                  'conv1d_590[0][0]',             \n",
      "                                                                  'conv1d_591[0][0]',             \n",
      "                                                                  'conv1d_592[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 80, 64)      256         ['concatenate_114[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 80, 64)       0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_593 (Conv1D)            (None, 80, 16)       1024        ['activation_152[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_115 (MaxPooling1  (None, 80, 64)      0           ['activation_152[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_594 (Conv1D)            (None, 80, 16)       4096        ['conv1d_593[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_595 (Conv1D)            (None, 80, 16)       2048        ['conv1d_593[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_596 (Conv1D)            (None, 80, 16)       1024        ['conv1d_593[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_597 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_115[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_115 (Concatenate)  (None, 80, 64)       0           ['conv1d_594[0][0]',             \n",
      "                                                                  'conv1d_595[0][0]',             \n",
      "                                                                  'conv1d_596[0][0]',             \n",
      "                                                                  'conv1d_597[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 80, 64)      256         ['concatenate_115[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 80, 64)       0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_598 (Conv1D)            (None, 80, 16)       1024        ['activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_116 (MaxPooling1  (None, 80, 64)      0           ['activation_153[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_599 (Conv1D)            (None, 80, 16)       4096        ['conv1d_598[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_600 (Conv1D)            (None, 80, 16)       2048        ['conv1d_598[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_601 (Conv1D)            (None, 80, 16)       1024        ['conv1d_598[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_602 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_116[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_116 (Concatenate)  (None, 80, 64)       0           ['conv1d_599[0][0]',             \n",
      "                                                                  'conv1d_600[0][0]',             \n",
      "                                                                  'conv1d_601[0][0]',             \n",
      "                                                                  'conv1d_602[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_603 (Conv1D)            (None, 80, 64)       64          ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 80, 64)      256         ['concatenate_116[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 80, 64)      256         ['conv1d_603[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 80, 64)       0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 80, 64)       0           ['batch_normalization_155[0][0]',\n",
      "                                                                  'activation_154[0][0]']         \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 80, 64)       0           ['add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_604 (Conv1D)            (None, 80, 16)       1024        ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_117 (MaxPooling1  (None, 80, 64)      0           ['activation_155[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_605 (Conv1D)            (None, 80, 16)       4096        ['conv1d_604[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_606 (Conv1D)            (None, 80, 16)       2048        ['conv1d_604[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_607 (Conv1D)            (None, 80, 16)       1024        ['conv1d_604[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_608 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_117[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_117 (Concatenate)  (None, 80, 64)       0           ['conv1d_605[0][0]',             \n",
      "                                                                  'conv1d_606[0][0]',             \n",
      "                                                                  'conv1d_607[0][0]',             \n",
      "                                                                  'conv1d_608[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 80, 64)      256         ['concatenate_117[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 80, 64)       0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_609 (Conv1D)            (None, 80, 16)       1024        ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_118 (MaxPooling1  (None, 80, 64)      0           ['activation_156[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_610 (Conv1D)            (None, 80, 16)       4096        ['conv1d_609[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_611 (Conv1D)            (None, 80, 16)       2048        ['conv1d_609[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_612 (Conv1D)            (None, 80, 16)       1024        ['conv1d_609[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_613 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_118[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_118 (Concatenate)  (None, 80, 64)       0           ['conv1d_610[0][0]',             \n",
      "                                                                  'conv1d_611[0][0]',             \n",
      "                                                                  'conv1d_612[0][0]',             \n",
      "                                                                  'conv1d_613[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 80, 64)      256         ['concatenate_118[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 80, 64)       0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_614 (Conv1D)            (None, 80, 16)       1024        ['activation_157[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_119 (MaxPooling1  (None, 80, 64)      0           ['activation_157[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_615 (Conv1D)            (None, 80, 16)       4096        ['conv1d_614[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_616 (Conv1D)            (None, 80, 16)       2048        ['conv1d_614[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_617 (Conv1D)            (None, 80, 16)       1024        ['conv1d_614[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_618 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_119[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_119 (Concatenate)  (None, 80, 64)       0           ['conv1d_615[0][0]',             \n",
      "                                                                  'conv1d_616[0][0]',             \n",
      "                                                                  'conv1d_617[0][0]',             \n",
      "                                                                  'conv1d_618[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_619 (Conv1D)            (None, 80, 64)       4096        ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 80, 64)      256         ['concatenate_119[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 80, 64)      256         ['conv1d_619[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 80, 64)       0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 80, 64)       0           ['batch_normalization_159[0][0]',\n",
      "                                                                  'activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 80, 64)       0           ['add_39[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_19 (G  (None, 64)          0           ['activation_159[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 3)            195         ['global_average_pooling1d_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,947\n",
      "Trainable params: 51,923\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 7s 222ms/step - loss: 1.1445 - accuracy: 0.4878 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.6634 - accuracy: 0.6707 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.5225 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 0.4434 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.4139 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 140ms/step - loss: 0.3971 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.3900 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.3693 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3719 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.3607 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 0.3358 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.3227 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.3103 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.2935 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.2880 - accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.2865 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.3048 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.2894 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.2736 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.2659 - accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.2639 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.2656 - accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 1s 145ms/step - loss: 0.2578 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2559 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2484 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 0.2608 - accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2386 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2204 - accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2286 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2060 - accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.2078 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2021 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.2045 - accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1925 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1926 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2048 - accuracy: 0.9146 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1765 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1877 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 1s 130ms/step - loss: 0.1708 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1558 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1637 - accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1477 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1370 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1241 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1351 - accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1260 - accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1509 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1149 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1061 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0999 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0823 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0933 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0882 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0953 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0934 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1987 - accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1321 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1668 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1507 - accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1411 - accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1027 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1018 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.1116 - accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0786 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0692 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0926 - accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0604 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.0461 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.0519 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0426 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 1s 143ms/step - loss: 0.0523 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.0490 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.0559 - accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.0484 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0320 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0387 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0398 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 1s 164ms/step - loss: 0.0297 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.0249 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0177 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0243 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0216 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 1s 146ms/step - loss: 0.0319 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0237 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 1s 160ms/step - loss: 0.0228 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0244 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0273 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.0262 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0310 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0297 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0214 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0285 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0179 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0237 - accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0179 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0137 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0108 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0147 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.0110 - accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.0098 - accuracy: 1.0000 - lr: 0.0010\n",
      "1/1 [==============================] - 0s 499ms/step\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 80, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d_120 (MaxPooling1  (None, 80, 1)       0           ['input_21[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_620 (Conv1D)            (None, 80, 16)       256         ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_621 (Conv1D)            (None, 80, 16)       128         ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_622 (Conv1D)            (None, 80, 16)       64          ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_623 (Conv1D)            (None, 80, 16)       16          ['max_pooling1d_120[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_120 (Concatenate)  (None, 80, 64)       0           ['conv1d_620[0][0]',             \n",
      "                                                                  'conv1d_621[0][0]',             \n",
      "                                                                  'conv1d_622[0][0]',             \n",
      "                                                                  'conv1d_623[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 80, 64)      256         ['concatenate_120[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 80, 64)       0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_624 (Conv1D)            (None, 80, 16)       1024        ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_121 (MaxPooling1  (None, 80, 64)      0           ['activation_160[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_625 (Conv1D)            (None, 80, 16)       4096        ['conv1d_624[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_626 (Conv1D)            (None, 80, 16)       2048        ['conv1d_624[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_627 (Conv1D)            (None, 80, 16)       1024        ['conv1d_624[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_628 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_121[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_121 (Concatenate)  (None, 80, 64)       0           ['conv1d_625[0][0]',             \n",
      "                                                                  'conv1d_626[0][0]',             \n",
      "                                                                  'conv1d_627[0][0]',             \n",
      "                                                                  'conv1d_628[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 80, 64)      256         ['concatenate_121[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 80, 64)       0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_629 (Conv1D)            (None, 80, 16)       1024        ['activation_161[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_122 (MaxPooling1  (None, 80, 64)      0           ['activation_161[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_630 (Conv1D)            (None, 80, 16)       4096        ['conv1d_629[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_631 (Conv1D)            (None, 80, 16)       2048        ['conv1d_629[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_632 (Conv1D)            (None, 80, 16)       1024        ['conv1d_629[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_633 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_122[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_122 (Concatenate)  (None, 80, 64)       0           ['conv1d_630[0][0]',             \n",
      "                                                                  'conv1d_631[0][0]',             \n",
      "                                                                  'conv1d_632[0][0]',             \n",
      "                                                                  'conv1d_633[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_634 (Conv1D)            (None, 80, 64)       64          ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 80, 64)      256         ['concatenate_122[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 80, 64)      256         ['conv1d_634[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 80, 64)       0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 80, 64)       0           ['batch_normalization_163[0][0]',\n",
      "                                                                  'activation_162[0][0]']         \n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 80, 64)       0           ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_635 (Conv1D)            (None, 80, 16)       1024        ['activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_123 (MaxPooling1  (None, 80, 64)      0           ['activation_163[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_636 (Conv1D)            (None, 80, 16)       4096        ['conv1d_635[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_637 (Conv1D)            (None, 80, 16)       2048        ['conv1d_635[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_638 (Conv1D)            (None, 80, 16)       1024        ['conv1d_635[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_639 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_123[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_123 (Concatenate)  (None, 80, 64)       0           ['conv1d_636[0][0]',             \n",
      "                                                                  'conv1d_637[0][0]',             \n",
      "                                                                  'conv1d_638[0][0]',             \n",
      "                                                                  'conv1d_639[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 80, 64)      256         ['concatenate_123[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_164 (Activation)    (None, 80, 64)       0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_640 (Conv1D)            (None, 80, 16)       1024        ['activation_164[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_124 (MaxPooling1  (None, 80, 64)      0           ['activation_164[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_641 (Conv1D)            (None, 80, 16)       4096        ['conv1d_640[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_642 (Conv1D)            (None, 80, 16)       2048        ['conv1d_640[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_643 (Conv1D)            (None, 80, 16)       1024        ['conv1d_640[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_644 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_124[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_124 (Concatenate)  (None, 80, 64)       0           ['conv1d_641[0][0]',             \n",
      "                                                                  'conv1d_642[0][0]',             \n",
      "                                                                  'conv1d_643[0][0]',             \n",
      "                                                                  'conv1d_644[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 80, 64)      256         ['concatenate_124[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 80, 64)       0           ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_645 (Conv1D)            (None, 80, 16)       1024        ['activation_165[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_125 (MaxPooling1  (None, 80, 64)      0           ['activation_165[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_646 (Conv1D)            (None, 80, 16)       4096        ['conv1d_645[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_647 (Conv1D)            (None, 80, 16)       2048        ['conv1d_645[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_648 (Conv1D)            (None, 80, 16)       1024        ['conv1d_645[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_649 (Conv1D)            (None, 80, 16)       1024        ['max_pooling1d_125[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_125 (Concatenate)  (None, 80, 64)       0           ['conv1d_646[0][0]',             \n",
      "                                                                  'conv1d_647[0][0]',             \n",
      "                                                                  'conv1d_648[0][0]',             \n",
      "                                                                  'conv1d_649[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_650 (Conv1D)            (None, 80, 64)       4096        ['activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 80, 64)      256         ['concatenate_125[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 80, 64)      256         ['conv1d_650[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 80, 64)       0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 80, 64)       0           ['batch_normalization_167[0][0]',\n",
      "                                                                  'activation_166[0][0]']         \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 80, 64)       0           ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_20 (G  (None, 64)          0           ['activation_167[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 3)            195         ['global_average_pooling1d_20[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,947\n",
      "Trainable params: 51,923\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 7s 171ms/step - loss: 0.7679 - accuracy: 0.6550 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.5577 - accuracy: 0.8275 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.4808 - accuracy: 0.8350 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.4435 - accuracy: 0.8325 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.3992 - accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.3823 - accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.3896 - accuracy: 0.8475 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.3850 - accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.3601 - accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.3504 - accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.3480 - accuracy: 0.8775 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.3330 - accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.3212 - accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.3281 - accuracy: 0.8725 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.3203 - accuracy: 0.8825 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.3109 - accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.3219 - accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.3055 - accuracy: 0.8725 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.3036 - accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.2850 - accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.3001 - accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.3126 - accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.2844 - accuracy: 0.8725 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.2830 - accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.2871 - accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.2654 - accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.2903 - accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.2871 - accuracy: 0.8725 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.2675 - accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 171ms/step - loss: 0.2535 - accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.2727 - accuracy: 0.8825 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.2661 - accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.2615 - accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.2595 - accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 0.2539 - accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.2423 - accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.2422 - accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 216ms/step - loss: 0.2508 - accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.2382 - accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.2220 - accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 2s 213ms/step - loss: 0.2102 - accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 0.2311 - accuracy: 0.9175 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.2201 - accuracy: 0.9350 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.2238 - accuracy: 0.9175 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.2023 - accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.2127 - accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.2032 - accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.1896 - accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.1830 - accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 2s 233ms/step - loss: 0.1769 - accuracy: 0.9425 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.2110 - accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 2s 223ms/step - loss: 0.2269 - accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.2214 - accuracy: 0.9125 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.2279 - accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.2140 - accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.1761 - accuracy: 0.9400 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 1s 160ms/step - loss: 0.1696 - accuracy: 0.9400 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.1637 - accuracy: 0.9425 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.1557 - accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 2s 267ms/step - loss: 0.1817 - accuracy: 0.9350 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 2s 213ms/step - loss: 0.1708 - accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 0.1509 - accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.1385 - accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.1359 - accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 0.1144 - accuracy: 0.9625 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.0963 - accuracy: 0.9775 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.1224 - accuracy: 0.9650 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 0.1078 - accuracy: 0.9625 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.0903 - accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 0.1105 - accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.1006 - accuracy: 0.9650 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.1286 - accuracy: 0.9525 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 1s 177ms/step - loss: 0.1649 - accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.1543 - accuracy: 0.9550 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.1536 - accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.1426 - accuracy: 0.9525 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.1155 - accuracy: 0.9700 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.1009 - accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.1185 - accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.1088 - accuracy: 0.9825 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 1s 208ms/step - loss: 0.0677 - accuracy: 0.9850 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.0876 - accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.0735 - accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 2s 200ms/step - loss: 0.0703 - accuracy: 0.9850 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.0624 - accuracy: 0.9825 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.0493 - accuracy: 0.9950 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.0382 - accuracy: 0.9925 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.0446 - accuracy: 0.9850 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.0435 - accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.0339 - accuracy: 0.9925 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.0331 - accuracy: 0.9950 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.0523 - accuracy: 0.9850 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 0.0426 - accuracy: 0.9950 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 1s 166ms/step - loss: 0.0922 - accuracy: 0.9700 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 0.0849 - accuracy: 0.9700 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 0.1265 - accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.1289 - accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 0.1687 - accuracy: 0.9425 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 0.1202 - accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.1295 - accuracy: 0.9600 - lr: 0.0010\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sofia\\Documents\\skola\\Project in Data Science\\DD2430-Project-Course-in-Data-Science\\src\\test_sofia.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sofia/Documents/skola/Project%20in%20Data%20Science/DD2430-Project-Course-in-Data-Science/src/test_sofia.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m ITC \u001b[39m=\u001b[39m InceptionTimeClassifier(n_epochs\u001b[39m=\u001b[39mN_EPOCHS, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, n_filters\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, bottleneck_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sofia/Documents/skola/Project%20in%20Data%20Science/DD2430-Project-Course-in-Data-Science/src/test_sofia.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m cross_val_obj \u001b[39m=\u001b[39m cross_validate(ITC, X\u001b[39m=\u001b[39mx_test, y\u001b[39m=\u001b[39my_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sofia/Documents/skola/Project%20in%20Data%20Science/DD2430-Project-Course-in-Data-Science/src/test_sofia.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m ITC\u001b[39m.\u001b[39;49mfit_predict(x_train, y_train, cv\u001b[39m=\u001b[39;49mcross_val_obj)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sofia/Documents/skola/Project%20in%20Data%20Science/DD2430-Project-Course-in-Data-Science/src/test_sofia.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(ITC\u001b[39m.\u001b[39msummary())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sofia/Documents/skola/Project%20in%20Data%20Science/DD2430-Project-Course-in-Data-Science/src/test_sofia.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Predict and evaluate on test set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sofia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sktime\\classification\\base.py:321\u001b[0m, in \u001b[0;36mBaseClassifier.fit_predict\u001b[1;34m(self, X, y, cv, change_state)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_predict\u001b[39m(\u001b[39mself\u001b[39m, X, y, cv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, change_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m    276\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit and predict labels for sequences in X.\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \n\u001b[0;32m    278\u001b[0m \u001b[39m    Convenience method to produce in-sample predictions and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39m        if cv is passed, -1 indicates entries not seen in union of test sets\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_predict_boilerplate(\n\u001b[0;32m    322\u001b[0m         X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, cv\u001b[39m=\u001b[39;49mcv, change_state\u001b[39m=\u001b[39;49mchange_state, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    323\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sofia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sktime\\classification\\base.py:381\u001b[0m, in \u001b[0;36mBaseClassifier._fit_predict_boilerplate\u001b[1;34m(self, X, y, cv, change_state, method)\u001b[0m\n\u001b[0;32m    379\u001b[0m y_pred[:] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mfor\u001b[39;00m tr_idx, tt_idx \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39;49msplit(X):\n\u001b[0;32m    382\u001b[0m         X_train \u001b[39m=\u001b[39m X[tr_idx]\n\u001b[0;32m    383\u001b[0m         X_test \u001b[39m=\u001b[39m X[tt_idx]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from sktime.classification.deep_learning import InceptionTimeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Train InceptionTimeClassifier on normal data\n",
    "N_EPOCHS = 100\n",
    "\n",
    "\n",
    "# class MyCallback(keras.callback.Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.history = {\"loss\":[], \"val_loss\":[]}\n",
    "#     def on_batch_end()\n",
    "\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"loss\", verbose=1, patience=5, start_from_epoch=50, min_delta=1e-3)\n",
    "callbacks=[early_stopping_callback]\n",
    "\n",
    "ITC = InceptionTimeClassifier(n_epochs=N_EPOCHS, verbose=1, kernel_size=16, n_filters=16, bottleneck_size=16)\n",
    "cross_val_obj = cross_validate(ITC, X=x_test, y=y_test)\n",
    "ITC.fit_predict(x_train, y_train, cv=cross_val_obj)\n",
    "\n",
    "\n",
    "print(ITC.summary())\n",
    "\n",
    "# Predict and evaluate on test set\n",
    "y_preditions = ITC.predict(x_test)\n",
    "\n",
    "\n",
    "accuracy_score(y_test, y_preditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test surrogate augmentation on InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the training data to be augmented\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "N = X_train.shape[0]\n",
    "p = 0.2     # percentage of data to augment\n",
    "rows_to_augment = random.sample(range(0,N), int(N*p))\n",
    "\n",
    "X_subset = deepcopy(X_test[rows_to_augment,:])\n",
    "y_subset = deepcopy(y_train[rows_to_augment])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrogate_augmentation import correlated_noise_surrogates, AAFT_surrogates, refined_AAFT_surrogates\n",
    "\n",
    "# Correlated noise surrogate\n",
    "X_subset_augmented = correlated_noise_surrogates(X_subset)\n",
    "X_train_augmented = np.concatenate((X_train, X_subset_augmented))\n",
    "y_train_augmented = np.concatenate((y_train, y_subset))\n",
    "\n",
    "\n",
    "ITC2 = InceptionTimeClassifier(n_epochs=N_EPOCHS, verbose=1)\n",
    "ITC2.fit(X_train_augmented, y_train_augmented)\n",
    "y_preditions = ITC2.predict(X_test)\n",
    "accuracy_score(y_test, y_preditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFT surrogates\n",
    "\n",
    "X_subset_augmented2 = AAFT_surrogates(X_subset)\n",
    "X_train_augmented2 = np.concatenate((X_train, X_subset_augmented2))\n",
    "\n",
    "ITC3 = InceptionTimeClassifier(n_epochs=N_EPOCHS, verbose=1)\n",
    "ITC3.fit(X_train_augmented2, y_train_augmented)\n",
    "y_preditions = ITC3.predict(X_test)\n",
    "accuracy_score(y_test, y_preditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAFT refined surrogates\n",
    "n_iters = 20\n",
    "\n",
    "X_subset_augmented3 = refined_AAFT_surrogates(X_subset, n_iterations=n_iters)\n",
    "X_train_augmented3 = np.concatenate((X_train, X_subset_augmented3), axis=0)\n",
    "\n",
    "ITC4 = InceptionTimeClassifier(n_epochs=N_EPOCHS, verbose=1, batch_size=BATCH_SIZE)\n",
    "ITC4.fit(X_train_augmented3, y_train_augmented)\n",
    "y_preditions = ITC4.predict(X_test)\n",
    "accuracy_score(y_test, y_preditions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
