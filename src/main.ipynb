{"cells":[{"cell_type":"markdown","metadata":{"id":"Jt7VuGE_BSlK"},"source":["# DD2430 Project: Data Augmentation Using Surrogates"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Imports\n","\n","\n","import tqdm\n","import numpy as np\n","import pandas as pd\n","import scipy as sp\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","import pyts"]},{"cell_type":"markdown","metadata":{},"source":["### Functions for loading or downloading data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WhZ_MVVV6sa3"},"outputs":[],"source":["\n","#!pip install pyts\n","#!pip install sktime\n","\n","#@title UCR auxiliary functions\n","\"\"\"\n","Utility functions for the UCR multivariate time series classification\n","archive.\n","\"\"\"\n","# Author: Johann Faouzi <johann.faouzi@gmail.com>\n","# License: BSD-3-Clause\n","\n","import numpy as np\n","import os\n","import pickle\n","from scipy.io.arff import loadarff\n","from sklearn.utils import Bunch\n","from urllib.request import urlretrieve\n","import zipfile\n","\n","\n","def _correct_ucr_name_download(dataset):\n","    if dataset == 'CinCECGtorso':\n","        return 'CinCECGTorso'\n","    elif dataset == 'MixedShapes':\n","        return 'MixedShapesRegularTrain'\n","    elif dataset == 'NonInvasiveFetalECGThorax1':\n","        return 'NonInvasiveFatalECGThorax1'\n","    elif dataset == 'NonInvasiveFetalECGThorax2':\n","        return 'NonInvasiveFatalECGThorax2'\n","    elif dataset == 'StarlightCurves':\n","        return 'StarLightCurves'\n","    else:\n","        return dataset\n","\n","\n","def _correct_ucr_name_description(dataset):\n","    if dataset == 'CinCECGTorso':\n","        return 'CinCECGtorso'\n","    elif dataset == 'MixedShapesRegularTrain':\n","        return 'MixedShapes'\n","    elif dataset == 'NonInvasiveFatalECGThorax1':\n","        return 'NonInvasiveFetalECGThorax1'\n","    elif dataset == 'NonInvasiveFatalECGThorax2':\n","        return 'NonInvasiveFetalECGThorax2'\n","    elif dataset == 'StarLightCurves':\n","        return 'StarlightCurves'\n","    else:\n","        return dataset\n","\n","\n","def ucr_dataset_list():\n","    \"\"\"List of available UCR datasets.\n","\n","    Returns\n","    -------\n","    datasets : list\n","        List of available datasets from the UCR Time Series\n","        Classification Archive.\n","\n","    References\n","    ----------\n","    .. [1] `List of datasets on the UEA & UCR archive\n","           <http://www.timeseriesclassification.com/dataset.php>`_\n","\n","    Examples\n","    --------\n","    >>> from pyts.datasets import ucr_dataset_list\n","    >>> ucr_dataset_list()[:3]\n","    ['ACSF1', 'Adiac', 'AllGestureWiimoteX']\n","\n","    \"\"\"\n","    module_path = os.path.dirname(__file__)\n","    finfo = os.path.join(module_path, 'info', 'ucr.pickle')\n","    dictionary = pickle.load(open(finfo, 'rb'))\n","    datasets = sorted(dictionary.keys())\n","    return datasets\n","\n","\n","def ucr_dataset_info(dataset=None):\n","    \"\"\"Information about the UCR datasets.\n","\n","    Parameters\n","    ----------\n","    dataset : str, list of str or None (default = None)\n","        The data sets for which the information will be returned.\n","        If None, the information for all the datasets is returned.\n","\n","    Returns\n","    -------\n","    dictionary : dict\n","        Dictionary with the information for each dataset.\n","\n","    References\n","    ----------\n","    .. [1] `List of datasets on the UEA & UCR archive\n","           <http://www.timeseriesclassification.com/dataset.php>`_\n","\n","    Examples\n","    --------\n","    >>> from pyts.datasets import ucr_dataset_info\n","    >>> ucr_dataset_info('Adiac')['n_classes']\n","    37\n","\n","    \"\"\"\n","    module_path = os.path.dirname(__file__)\n","    finfo = os.path.join(module_path, 'info', 'ucr.pickle')\n","    dictionary = pickle.load(open(finfo, 'rb'))\n","    datasets = list(dictionary.keys())\n","\n","    if dataset is None:\n","        return dictionary\n","    elif isinstance(dataset, str):\n","        if dataset not in datasets:\n","            raise ValueError(\n","                \"{0} is not a valid name. The list of available names \"\n","                \"can be obtained by calling the \"\n","                \"'pyts.datasets.ucr_dataset_list' function.\"\n","                .format(dataset)\n","            )\n","        else:\n","            return dictionary[dataset]\n","    elif isinstance(dataset, (list, tuple, np.ndarray)):\n","        dataset = np.asarray(dataset)\n","        invalid_datasets = np.setdiff1d(dataset, datasets)\n","        if invalid_datasets.size > 0:\n","            raise ValueError(\n","                \"The following names are not valid: {0}. The list of \"\n","                \"available names can be obtained by calling the \"\n","                \"'pyts.datasets.ucr_dataset_list' function.\"\n","                .format(invalid_datasets)\n","            )\n","        else:\n","            info = {}\n","            for data in dataset:\n","                info[data] = dictionary[data]\n","            return info\n","\n","\n","def fetch_ucr_dataset(dataset, use_cache=True, data_home=None,\n","                      return_X_y=False):\n","    r\"\"\"Fetch dataset from UCR TSC Archive by name.\n","\n","    Fetched data sets are automatically saved in the\n","    ``pyts/datasets/_cached_datasets`` folder. To avoid\n","    downloading the same data set several times, it is\n","    highly recommended not to change the default values\n","    of ``use_cache`` and ``path``.\n","\n","    Parameters\n","    ----------\n","    dataset : str\n","        Name of the dataset.\n","\n","    use_cache : bool (default = True)\n","        If True, look if the data set has already been fetched\n","        and load the fetched version if it is the case. If False,\n","        download the data set from the UCR Time Series Classification\n","        Archive.\n","\n","    data_home : None or str (default = None)\n","        The path of the folder containing the cached data set.\n","        If None, the ``pyts.datasets.cached_datasets/UCR/`` folder is\n","        used. If the data set is not found, it is downloaded and cached\n","        in this path.\n","\n","    return_X_y : bool (default = False)\n","        If True, returns ``(data_train, data_test, target_train, target_test)``\n","        instead of a Bunch object. See below for more information about the\n","        `data` and `target` object.\n","\n","    Returns\n","    -------\n","    data : Bunch\n","        Dictionary-like object, with attributes:\n","\n","        data_train : array of floats\n","            The time series in the training set.\n","        data_test : array of floats\n","            The time series in the test set.\n","        target_train : array of integers\n","            The classification labels in the training set.\n","        target_test : array of integers\n","            The classification labels in the test set.\n","        DESCR : str\n","            The full description of the dataset.\n","        url : str\n","            The url of the dataset.\n","\n","    (data_train, data_test, target_train, target_test) : tuple if ``return_X_y`` is True\n","\n","    Notes\n","    -----\n","    Missing values are represented as NaN's.\n","\n","    References\n","    ----------\n","    .. [1] H. A. Dau et al, \"The UCR Time Series Archive\".\n","           arXiv:1810.07758 [cs, stat], 2018.\n","\n","    .. [2] A. Bagnall et al, \"The UEA & UCR Time Series Classification\n","           Repository\", www.timeseriesclassification.com.\n","\n","    \"\"\"  # noqa: E501\n","    if dataset not in ucr_dataset_list():\n","        raise ValueError(\n","            \"{0} is not a valid name. The list of available names \"\n","            \"can be obtained with ``pyts.datasets.ucr_dataset_list()``\"\n","            .format(dataset)\n","        )\n","    if data_home is None:\n","        import pyts\n","        home = '/'.join(pyts.__file__.split('/')[:-2]) + '/'\n","        relative_path = 'pyts/datasets/cached_datasets/UCR/'\n","        path = home + relative_path\n","    else:\n","        path = data_home\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","    correct_dataset = _correct_ucr_name_download(dataset)\n","    if use_cache and os.path.exists(os.path.join(path, correct_dataset)):\n","        bunch = _load_ucr_dataset(correct_dataset, path=path)\n","    else:\n","        # CHANGED LINE --------\n","        # url = (\"http://www.timeseriesclassification.com/Downloads/{0}.zip\"\n","        # url = (\"http://www.timeseriesclassification.com/ClassificationDownloads/{0}.zip\".format(correct_dataset))\n","        url = (\"https://www.timeseriesclassification.com/aeon-toolkit/{0}.zip\".format(correct_dataset))\n","\n","        # ---------------------\n","        temp_filename = 'temp_{}'.format(correct_dataset)\n","        temp_file_path = os.path.join(path, temp_filename)\n","        _ = urlretrieve(url, temp_file_path)\n","        zipfile.ZipFile(temp_file_path).extractall(os.path.join(path, correct_dataset))\n","        os.remove(temp_file_path)\n","        bunch = _load_ucr_dataset(correct_dataset, path)\n","\n","    if return_X_y:\n","        return (bunch.data_train, bunch.data_test,\n","                bunch.target_train, bunch.target_test)\n","    return bunch\n","\n","\n","def _load_ucr_dataset(dataset, path):\n","    \"\"\"Load a UCR data set from a local folder.\n","\n","    Parameters\n","    ----------\n","    dataset : str\n","        Name of the dataset.\n","\n","    path : str\n","        The path of the folder containing the cached data set.\n","\n","    Returns\n","    -------\n","    data : Bunch\n","        Dictionary-like object, with attributes:\n","\n","        data_train : array of floats\n","            The time series in the training set.\n","        data_test : array of floats\n","            The time series in the test set.\n","        target_train : array\n","            The classification labels in the training set.\n","        target_test : array\n","            The classification labels in the test set.\n","        DESCR : str\n","            The full description of the dataset.\n","        url : str\n","            The url of the dataset.\n","\n","    Notes\n","    -----\n","    Padded values are represented as NaN's.\n","\n","    \"\"\"\n","    new_path = os.path.join(path, dataset) + '/'\n","    try:\n","        with(open(new_path + dataset + '.txt', encoding='utf-8')) as f:\n","            description = f.read()\n","    except UnicodeDecodeError:\n","        with(open(new_path + dataset + '.txt', encoding='ISO-8859-1')) as f:\n","            description = f.read()\n","    try:\n","        data_train = np.genfromtxt(new_path + dataset + '_TRAIN.txt')\n","        data_test = np.genfromtxt(new_path + dataset + '_TEST.txt')\n","\n","        X_train, y_train = data_train[:, 1:], data_train[:, 0]\n","        X_test, y_test = data_test[:, 1:], data_test[:, 0]\n","\n","    except IndexError:\n","        train = loadarff(new_path + dataset + '_TRAIN.arff')\n","        test = loadarff(new_path + dataset + '_TEST.arff')\n","\n","        data_train = np.asarray([train[0][name] for name in train[1].names()])\n","        X_train = data_train[:-1].T.astype('float64')\n","        y_train = data_train[-1]\n","\n","        data_test = np.asarray([test[0][name] for name in test[1].names()])\n","        X_test = data_test[:-1].T.astype('float64')\n","        y_test = data_test[-1]\n","\n","    try:\n","        y_train = y_train.astype('float64').astype('int64')\n","        y_test = y_test.astype('float64').astype('int64')\n","    except ValueError:\n","        y_train = y_train.astype(str)\n","        y_test = y_test.astype(str)\n","\n","    bunch = Bunch(\n","        data_train=X_train, target_train=y_train,\n","        data_test=X_test, target_test=y_test,\n","        DESCR=description,\n","        url=(\"http://www.timeseriesclassification.com/\"\n","             \"description.php?Dataset={}\".format(dataset))\n","    )\n","\n","    return bunch"]},{"cell_type":"markdown","metadata":{"id":"HDVfBraQBx_v"},"source":["### Load and prepare datasets "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"VX15CPC94fzo"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Adiac']\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  5.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["{'data_train': array([[1.5980065, 1.5994389, 1.5705294, ..., 1.5641545, 1.5708545,\n","        1.5928905],\n","       [1.7011457, 1.670645 , 1.6188844, ..., 1.5197372, 1.6025179,\n","        1.6701904],\n","       [1.722342 , 1.6953288, 1.6569459, ..., 1.6418088, 1.6949728,\n","        1.7084884],\n","       ...,\n","       [2.5955985, 2.6250629, 2.4239586, ..., 2.1440004, 2.1288939,\n","        2.1176354],\n","       [1.6598998, 1.6441473, 1.5937788, ..., 1.5798671, 1.636902 ,\n","        1.6601968],\n","       [1.7266289, 1.7288809, 1.7116989, ..., 1.5963694, 1.6403326,\n","        1.6988142]]), 'target_train': array([22, 28, 21, 15,  2, 18, 21, 36, 11, 21, 29, 26,  1,  9, 17,  7, 36,\n","       25, 11, 10, 25, 14,  3,  4, 36,  4,  4, 12, 23, 23,  6, 22,  8, 25,\n","       21, 34, 33, 28,  1, 24,  2, 37, 32, 37, 12, 17,  6, 11,  4, 29, 20,\n","        2, 27, 17, 20, 32, 25, 30, 31, 34, 16, 32, 28, 23, 15, 20, 24, 11,\n","       35, 36, 26, 12, 18, 28,  2, 14,  7, 28, 34, 27, 31, 31, 35,  9, 19,\n","       36, 12, 10, 10,  7, 14, 15, 10, 15,  6,  4, 32, 17, 23, 33, 19, 33,\n","       18, 22, 34,  9, 10, 15, 32, 30, 10, 14,  1, 27, 16, 36, 24, 22, 32,\n","       15,  2,  4, 26, 27, 12, 16, 28, 24, 23, 37, 13,  4,  8, 14, 31, 24,\n","       29, 27, 35,  6,  2, 34,  1, 32,  6, 26, 33, 21,  4, 11,  8, 30,  7,\n","       17, 20, 16,  2, 11, 25,  5, 36, 13,  3, 12,  2, 18, 12, 37, 27, 28,\n","       24, 24, 11, 21, 20, 14, 28, 10, 22,  9, 12, 24,  6, 17,  9, 26, 27,\n","        5, 25, 19,  7, 14, 20, 19, 24,  7,  1, 31, 21, 22, 24, 30, 29,  8,\n","       15, 20, 37, 12, 18, 16, 17,  5, 33, 12, 14,  6, 28, 34, 14,  7,  6,\n","       32, 25, 16,  9, 37, 35, 18, 36, 35,  2,  9, 19, 33,  4,  2, 14, 36,\n","       15, 19, 35,  6, 25, 11, 15, 23, 10, 20, 25,  6,  1,  4, 22, 26, 17,\n","       23, 10, 29,  7, 30,  3, 22, 33, 16, 13, 27, 16, 29, 19, 19,  1, 28,\n","        1, 30,  8,  5,  1,  3, 27,  1, 11, 29,  4,  4,  6, 28, 24, 21, 27,\n","       26, 36, 33, 18,  8, 17, 35, 32, 33,  8, 30,  8, 35, 31, 30,  8,  8,\n","       13, 30, 32,  8,  7, 25, 12, 23, 14, 27, 11, 24, 10, 26, 18, 19,  9,\n","       18, 32, 34, 10,  4, 25, 28, 19, 32, 12,  4,  1, 20, 27, 35, 32, 13,\n","       19, 16, 30, 31, 15,  3, 17, 36,  1, 31, 13, 24, 27, 29, 26, 30,  8,\n","       22, 30, 34, 33, 37, 37,  1, 19, 15, 35, 17, 24, 19, 29, 23, 22, 15,\n","       19, 33,  9, 34, 16,  8, 24, 33, 30,  7, 25, 31, 33,  6, 28, 25],\n","      dtype=int64), 'data_test': array([[1.374884 , 1.2894387, 1.2043045, ..., 1.6103982, 1.53924  ,\n","        1.4519241],\n","       [1.339994 , 1.2353184, 1.1320378, ..., 1.6572156, 1.5480958,\n","        1.4413616],\n","       [1.6741981, 1.6438445, 1.5707222, ..., 1.5604672, 1.6344822,\n","        1.6737078],\n","       ...,\n","       [1.6519997, 1.6967991, 1.7005604, ..., 1.499251 , 1.5557159,\n","        1.6203831],\n","       [1.3986733, 1.2933925, 1.1888369, ..., 1.6363385, 1.5626484,\n","        1.4605437],\n","       [1.7271724, 1.7283587, 1.6937594, ..., 1.6272951, 1.6753428,\n","        1.6989307]]), 'target_test': array([16, 36, 34, 22, 16, 31, 24,  2, 30, 14, 24, 14, 25, 18, 32, 28, 18,\n","       26, 31, 37, 10, 31, 21, 14, 34,  3,  2, 29, 32, 32,  5, 12, 20, 18,\n","       36, 35, 37, 20,  7, 11, 12, 12,  8,  6, 12, 15,  7, 20, 25, 16, 14,\n","       15, 13, 36, 31, 12, 25, 27, 20, 10, 18, 17, 13, 23,  2, 11, 24, 18,\n","        7, 12,  3, 12, 36,  2, 12, 21, 23,  5, 15,  2, 26,  6, 26, 10,  2,\n","       10, 22,  4, 22, 31, 29,  3, 18, 11, 25, 31,  5, 20, 28, 36,  6, 31,\n","       21, 24, 17, 29, 19, 15, 21, 26, 34, 29, 22, 21, 21,  1, 22,  3, 35,\n","        3, 19,  6, 37, 25,  5,  8,  5,  3, 28, 14, 15, 25, 34,  9, 11, 21,\n","       23, 15, 18, 36, 19, 11, 33, 20, 36, 16, 33, 37, 19, 17, 26, 34, 14,\n","       13, 19, 35, 16, 14, 37, 25,  5,  5, 17, 19, 27, 37, 13, 35,  4, 35,\n","       34, 28, 13,  3,  3, 21, 18,  2, 18, 36,  7,  3, 25,  3, 29,  4, 20,\n","        8, 13, 33, 35,  1, 34, 37, 25, 30,  1, 36,  8, 35, 24,  9, 26, 11,\n","       33, 26, 23, 36, 24,  3, 23,  5, 17, 21, 12, 22, 11, 17, 10,  8, 10,\n","        8, 21, 31, 30, 37, 23,  5, 12, 15, 20, 35, 12, 35,  5, 23, 28, 27,\n","        6,  2,  7,  5,  9, 13, 37, 32,  2, 29, 23, 19, 29, 32,  9, 30, 12,\n","       33, 16,  9,  6,  2,  3,  5, 22, 15, 23,  7, 12,  7, 22, 19, 25,  4,\n","       25, 16, 27,  3, 16, 11, 31, 16, 25, 13, 19, 34, 24, 30, 27,  2, 32,\n","       30, 17, 25, 36, 10,  7, 26, 22,  8, 34,  8,  7, 25,  1,  8,  9, 13,\n","        5, 37, 17, 18, 23,  3,  1,  9, 19, 13, 27, 31, 13, 14, 23, 12, 21,\n","       20, 33,  6,  4, 26, 29, 14, 13, 13, 25,  5, 20, 11, 21, 33, 22, 11,\n","       29,  9, 18,  2,  8, 34, 19, 26,  3, 13, 18, 27,  9,  8, 10, 32, 28,\n","        7, 29, 36,  8,  4, 30, 26,  6, 19,  9,  1, 34, 17, 36,  5, 18, 24,\n","        9, 20, 31, 15, 29, 37, 20, 37,  2, 28, 16,  1, 25, 35,  5, 36, 10],\n","      dtype=int64), 'DESCR': 'The Automatic Diatom Identification and Classification (ADIAC)\\nproject was a pilot study concerning automatic identification of\\ndiatoms (unicellular algae) on the basis of images. The data was\\ndonated by Andrei Jalba, a PhD student on the project, which\\nfinished in the early 2000s. The outlines are extracted from\\nthresholded images. Presumably the time series are generated as\\ndistance to a reference point (the centre being the obvious\\ncandidate). The data is very sinusoidal\\n', 'url': 'http://www.timeseriesclassification.com/description.php?Dataset=Adiac'}\n"]}],"source":["# Load Data\n","\n","from pyts.datasets import ucr_dataset_list\n","\n","dataset_name_list = ucr_dataset_list()[1:2]\n","print(dataset_name_list)  \n","CACHED_DATA_FOLDER = os.path.join(os.path.dirname(os.getcwd()), \"Data\")\n","dataset_list = []\n","for dataset_name in tqdm.tqdm(dataset_name_list):\n","\n","    cache_path = os.path.join(CACHED_DATA_FOLDER, dataset_name)\n","    datset = fetch_ucr_dataset(dataset=dataset_name, use_cache=True, data_home=cache_path)\n","    dataset_list.append(datset)\n","\n","\n","## Create pandas dataframe\n","dataset_list_binary = []\n","dataset_train_size = []\n","dataset_test_size = []\n","datset_length = []\n","binary_dataset_name = []\n","test_balance = []\n","\n","for i,dataset_object in enumerate(dataset_list):\n","\n","    print(dataset_object)\n","    # Filter the datasets depending on number of classes\n","    num_clases = len(np.unique(dataset_object['target_train']))\n","    if num_clases < 3:\n","        name = dataset_name_list[i]\n","        dataset_list_binary.append(dataset_object)\n","        data_length = dataset_object['data_train'].shape[1]\n","        train_size = dataset_object['data_train'].shape[0]\n","        test_size = dataset_object['data_test'].shape[0]\n","        (labels,counts) = np.unique(dataset_object['target_test'],return_counts=True)\n","        test_proportion = counts[0]/(counts[0]+counts[1])\n","\n","        datset_length.append(data_length)\n","        dataset_train_size.append(train_size)\n","        dataset_test_size.append(test_size)\n","        binary_dataset_name.append(name)\n","        test_balance.append(test_proportion)\n","\n","d = {'name': binary_dataset_name, 'train_size': dataset_train_size, 'test_size': dataset_test_size,'length':datset_length, 'test_balance':test_balance}\n","df = pd.DataFrame(data=d)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":0}
